
CIS 520 - Programming Project #1

                   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Dalton Graber <dgraber95@ksu.edu>
Alex Hamilton <ash7@ksu.edu>
Nolan Casimir <casimirn@ksu.edu>
...

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for
>> the TA, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation,
>> course text, lecture notes, and course staff.

https://knowledgejunk.net/2011/05/06/avoiding-busy-wait-in-timer_sleep-on-pintos/
https://github.com/ryantimwilson/Pintos-Project-1

                 ALARM CLOCK
                 ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

pintos/src/devices/timer.c:
/* List of sleeping threads */
static struct list sleep_list;

/* Lock for list of sleeping threads */
static struct lock sleep_list_lock;

pintos/src/threads/thread.h:
struct thread
  {
  ...
  /* Sleeping elements */
  struct list_elem sleep_elem;        /* Sleeping list element */
  int64_t sleep_ticks;                /* Tick count to sleep for */
  ...
  };

  
  
---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to your timer_sleep(),
>> including the effects of the timer interrupt handler.

Firstly, interrupts are disabled. Then, the current thread has its "sleep_ticks"
struct member set to the timer_sleep "ticks" argument. The thread is then added 
to the list of sleeping threads, the thread is blocked, then interrupts are reenabled
once the thread wakes up.
 
In the timer interrupt handler, we iterate over the list of sleeping threads, 
decrementing the sleep count each time. If, after decrementing the sleep count,
the count is 0, we remove the thread from the list of sleeping threads, and 
unblock that thread. 



>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

To decrease time spent in the timer interrupt handler, we used a doubly linked
list structure to keep track of our sleeping threads, as opposed to an 
array/list of all threads. This way, we aren't wasting any time looking at
threads which are not sleeping. 



---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

We are avoiding race conditions when multiple threads call timer_sleep by
placing a sleep_list_lock on the current thread before pushing it to the
back of the sleep_list. This way, only one thread can be accessing timer_sleep()
at a time.



>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

We are avoiding race conditions when a timer interrupt occurs by
disabling interupts at the begining of the timer_sleep function.
This ensures timer_interrupt does not occur during the execution of
timer_sleep.



---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> other designs that you considered?

When we originally started the project, we had no idea where to begin. We
looked online and found a design that DID avoid busy waiting, but was
horribly inefficient. It added a sleep_ticks elem to the thread struct
that it would update and then in the timer interrupt, it would search through
EVERY thread to see if it should wake it up. Well, not EVERY thread was trying
to sleep. We spun a homebrewed variant of this design but added a list_elem
field to the thread struct in addition the sleep_ticks count. This allowed us 
to create a separate list exclusively for sleeping threads. That way during
timer interrupts, we are only checking sleeping threads instead of ALL threads.
On a system with hundreds (or thousands) of threads, this can save a LOT of CPU 
time when we consider this search was occuring EVERY SINGLE timer tick.



             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

pintos/src/threads/thread.h:
struct thread
  {
    ...
    /* Priority Donation Fields */
    int original_priority;          /* Keeps track of thread's original priority                    */
    struct list_elem donor_card;    /* List element to be inserted into list of priority recipient  */
    struct list donor_list;         /* List of threads donating to this thread                      */
    struct lock *recipient_lock;    /* Pointer to desired lock                                      */
    ...
  };



>> B2: Explain the data structure used to track priority donation.

We used a (sorted) list struct in our thread struct so any given thread can keep track of the
thread donors which have donated their priorities to that thread. To belong in a donor list,
every thread needed a 'donor_card' which has a reference to the donating thread. In addition,
a reference is kept to a lock which this given thread is waiting to acquire. This way, we can
keep track of where any thread's priority is going.



---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

We regularly sort the semaphore 'waiters' list by priority (low to high)
and then wake up the thread on the back of the list (which will have the
highest priority).



>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

The first thing to do in lock_acquire is check if the lock currently has a holder.
If so, we point the current thread's recipient_lock struct member to the lock we
are trying to acquire, and then add the current thread to the donor list of the
thread holding the lock. During the call to sema_down in lock_acquire, if the thread
trying to acquire the lock must wait in the semaphore's waiting list, we call another
method, thread_donate_priority(). This method traverses (max) 8 layers down from the 
current thread, by way of each threads' 'recipient_lock' pointer, and gives each of 
those threads the current thread's priority. After this has completed, the current
thread is blocked in sema_down, as before. 



>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

In lock_release(), we traverse the donor list of the current thread, and
remove any threads which are waiting on the lock being released. Once any 
necessary threads have been removed, the current thread's priority is updated
by setting it to the highest priority of any of its donors, or its original 
priority if this current thread has no donors. After this, lock->holder is reset,
and sema_up() is called, which sorts the waiters list and wakes up the thread in the
waiters list with the highest priority. 



---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

Situation: a thread is currently modifying its priority when an interrupt occurs
that modifies the donor_list. This could cause the current_thread to incorrectly
set its priority (if the new donor is higher priority).
This is handled by disabling interrupts at the beginning of thread_set_priority
and reenabling them as the final responsibility of the function.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

When we began working, we drew out several use cases on a white board and determined
the desired behavior. After implementing what we thought was our desired behavior,
we were unable to pass a few of the provided priority test. We were nearly there
and looked online for a little help. We were able to find a solution that was similar
in design to what we had been working on. We realized we had majorly overcomplicated
the problem by trying to swap priorities back and forth, and pass priorities back to
their original owner. It was much easier to just keep track of the original priority
and revert back to that once we were done with donors. Never forget: "KISS" - Keep It
Simple, Stupid!

              ADVANCED SCHEDULER [EXTRA CREDIT]
              =================================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0
 4
 8
12
16
20
24
28
32
36

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

